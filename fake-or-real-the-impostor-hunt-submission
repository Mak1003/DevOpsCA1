{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":105874,"databundleVersionId":12964783,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================\n# 1. Import libraries\n# ============================================\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport os\n\n# ============================================\n# 2. Load training metadata\n# ============================================\ntrain_path = \"/kaggle/input/fake-or-real-the-impostor-hunt/data/train.csv\"\ntrain_df = pd.read_csv(train_path)\n\nprint(\"Train shape:\", train_df.shape)\nprint(train_df.head())\n\n# ============================================\n# 3. Load test dataset (loop through txt files)\n# ============================================\ntest_dir = \"/kaggle/input/fake-or-real-the-impostor-hunt/data/test\"\n\ntest_data = []\nfor article_id in os.listdir(test_dir):\n    article_path = os.path.join(test_dir, article_id)\n    if os.path.isdir(article_path):\n        for file_name in os.listdir(article_path):\n            file_path = os.path.join(article_path, file_name)\n            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                text = f.read()\n            test_data.append({\n                \"article_id\": article_id,\n                \"file_id\": file_name,\n                \"text\": text\n            })\n\ntest_df = pd.DataFrame(test_data)\nprint(\"Test shape:\", test_df.shape)\nprint(test_df.head())\n\n# ============================================\n# 4. Build text dataset for training\n# ============================================\n# Each training row says which is the real text\n# We must map \"id\" + \"real_text_id\" -> actual text from test set\n\n# Merge with texts\ntrain_full = []\nfor _, row in train_df.iterrows():\n    aid = f\"article_{row['id']:04d}\"\n    real_file = f\"file_{row['real_text_id']}.txt\"\n\n    # real label\n    real_text = test_df[(test_df.article_id == aid) & (test_df.file_id == real_file)][\"text\"].values[0]\n    train_full.append({\"id\": row[\"id\"], \"text\": real_text, \"label\": 1})\n\n    # fake label (the *other* file)\n    fake_file = \"file_1.txt\" if row[\"real_text_id\"] == 2 else \"file_2.txt\"\n    fake_text = test_df[(test_df.article_id == aid) & (test_df.file_id == fake_file)][\"text\"].values[0]\n    train_full.append({\"id\": row[\"id\"], \"text\": fake_text, \"label\": 0})\n\ntrain_full = pd.DataFrame(train_full)\nprint(\"Expanded train shape:\", train_full.shape)\nprint(train_full.head())\n\n# ============================================\n# 5. TF-IDF + Logistic Regression\n# ============================================\nX = train_full[\"text\"].fillna(\"\")\ny = train_full[\"label\"]\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\ntfidf = TfidfVectorizer(stop_words=\"english\", max_features=5000)\nX_train_tfidf = tfidf.fit_transform(X_train)\nX_val_tfidf   = tfidf.transform(X_val)\n\nmodel = LogisticRegression(max_iter=300, random_state=42)\nmodel.fit(X_train_tfidf, y_train)\n\nval_preds = model.predict(X_val_tfidf)\nprint(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\n\n# ============================================\n# 6. Predict real text for each test article\n# ============================================\nsubmission_rows = []\nfor aid, group in test_df.groupby(\"article_id\"):\n    texts = group[\"text\"].tolist()\n    files = group[\"file_id\"].tolist()\n\n    X_test = tfidf.transform(texts)\n    preds = model.predict_proba(X_test)[:,1]  # probability of real\n\n    best_idx = np.argmax(preds)\n    best_file = files[best_idx]\n\n    # Convert file_1.txt -> 1, file_2.txt -> 2\n    real_text_id = 1 if \"file_1\" in best_file else 2\n    article_num = int(aid.replace(\"article_\", \"\"))\n\n    submission_rows.append({\"id\": article_num, \"real_text_id\": real_text_id})\n\nsubmission = pd.DataFrame(submission_rows).sort_values(\"id\")\nsubmission.to_csv(\"submission.csv\", index=False)\n\nprint(\"✅ submission.csv saved\")\nprint(submission.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:08:24.924039Z","iopub.execute_input":"2025-09-01T14:08:24.924942Z","iopub.status.idle":"2025-09-01T14:08:31.212996Z","shell.execute_reply.started":"2025-09-01T14:08:24.924909Z","shell.execute_reply":"2025-09-01T14:08:31.212186Z"}},"outputs":[{"name":"stdout","text":"Train shape: (95, 2)\n   id  real_text_id\n0   0             1\n1   1             2\n2   2             1\n3   3             2\n4   4             2\nTest shape: (2136, 3)\n     article_id     file_id                                               text\n0  article_0192  file_2.txt  Stars with lower masses than our sun experienc...\n1  article_0192  file_1.txt  Low or intermediate sized stars (like our sun)...\n2  article_0956  file_2.txt  In the text, we examined the data-cube in the ...\n3  article_0956  file_1.txt  In the text, we examined the data-cube in the ...\n4  article_0266  file_2.txt  Spectra used by astronomers across various fie...\nExpanded train shape: (190, 3)\n   id                                               text  label\n0   0  \"Music\" Music music music Music music Music mu...      1\n1   0  Since its launch on Paranal observatory's Very...      0\n2   1  SN 1987A provides valuable insights as newer o...      1\n3   1  underground exploration on SN's birth has prov...      0\n4   2  This research aimed to understand how star sha...      1\nValidation Accuracy: 0.34210526315789475\n✅ submission.csv saved\n   id  real_text_id\n0   0             1\n1   1             2\n2   2             1\n3   3             2\n4   4             2\n","output_type":"stream"}],"execution_count":35}]}